{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# DEXI YOLO Training Tutorial - Google Colab\n\nüåü **Welcome to Google Colab!** This notebook will train a custom YOLO object detection model for drone detection using **free GPU acceleration**.\n\n**üìã Before you start:**\n1. **Enable GPU**: Go to `Runtime` ‚Üí `Change runtime type` ‚Üí `Hardware accelerator` ‚Üí `GPU`\n2. **Upload your files**: Use the file browser on the left to upload your 6 base images\n3. **Run all cells**: The notebook will handle everything automatically!\n\n## üéØ What you'll accomplish:\n- Train a **99.5% accurate** YOLO model\n- Generate **900+ augmented images** from 6 originals\n- Complete training in **15-25 minutes** (with GPU)\n- Download **PyTorch (.pt)** and **ONNX** models for deployment\n\n## üìã Table of Contents\n1. [Colab Setup & GPU Check](#1-colab-setup--gpu-check)\n2. [File Upload & Dataset Preparation](#2-file-upload--dataset-preparation)\n3. [Data Augmentation](#3-data-augmentation)\n4. [YOLO Training](#4-yolo-training)\n5. [Results Analysis](#5-results-analysis)\n6. [Model Testing](#6-model-testing)\n7. [ONNX Conversion & Download](#7-onnx-conversion--download)\n\n---\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's make sure we have all the required packages installed and import the necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Colab Setup & GPU Check\n\nLet's verify that we're running on Google Colab with GPU acceleration enabled.\"",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# üåü Verify Google Colab Environment and GPU\\nimport torch\\nimport os\\n\\n# Check if we're on Colab\\ntry:\\n    import google.colab\\n    print(\\\"üåü Google Colab detected!\\\")\\n    \\n    # Check GPU availability\\n    if torch.cuda.is_available():\\n        gpu_name = torch.cuda.get_device_name(0)\\n        print(f\\\"üöÄ GPU detected: {gpu_name}\\\")\\n        print(f\\\"üìä GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\\\")\\n        device = 'cuda'\\n    else:\\n        print(\\\"‚ö†Ô∏è  NO GPU DETECTED!\\\")\\n        print(\\\"üîß To enable GPU: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\\\")\\n        print(\\\"‚ö° GPU will make training 10-20x faster!\\\")\\n        device = 'cpu'\\n        \\nexcept ImportError:\\n    print(\\\"‚ùå This notebook is designed for Google Colab\\\")\\n    print(\\\"üí° For local usage, use: YOLO_Training_Tutorial_Local.ipynb\\\")\\n    device = 'cpu'\\n\\nprint(f\\\"\\\\nüîß Using device: {device}\\\")\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "## 2. File Upload & Dataset Preparation\\n\\nNow let's upload your files and set up the dataset structure.\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üì¶ Install required packages for Colab\\nprint(\\\"üì¶ Installing YOLO and dependencies...\\\")\\n!pip install ultralytics opencv-python matplotlib pandas -q\\n\\n# Create directory structure\\nprint(\\\"üìÅ Creating directory structure...\\\")\\n!mkdir -p train/images train/labels val/images val/labels\\n\\nprint(\\\"‚úÖ Package installation complete!\\\")\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from IPython.display import Image, display\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Set matplotlib style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else 'Not available'}\")\n",
    "\n",
    "# Determine the best device to use\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# üìÅ Upload your files to Colab\\nfrom google.colab import files\\nimport os\\n\\nprint(\\\"üì§ Upload Required Files:\\\")\\nprint(\\\"\\\\n1Ô∏è‚É£ First, upload your support files:\\\")\\nprint(\\\"   ‚Ä¢ dataset.yaml\\\")\\nprint(\\\"   ‚Ä¢ augment_dataset.py\\\")\\nprint(\\\"   ‚Ä¢ convert_to_onnx.py (optional)\\\")\\n\\n# File upload widget\\nprint(\\\"\\\\n‚¨ÜÔ∏è Click 'Choose Files' below to upload:\\\")\\nuploaded = files.upload()\\n\\nprint(f\\\"\\\\n‚úÖ Uploaded {len(uploaded)} files\\\")\\nfor filename in uploaded.keys():\\n    print(f\\\"   üìÑ {filename} ({len(uploaded[filename])} bytes)\\\")\\n\\nprint(\\\"\\\\n2Ô∏è‚É£ Next, upload your 6 base images to train/images/:\\\")\\nprint(\\\"   ‚Ä¢ Use the file browser on the left (üìÅ icon)\\\")\\nprint(\\\"   ‚Ä¢ Navigate to train/images/ folder\\\")\\nprint(\\\"   ‚Ä¢ Upload: bird.jpg, car.jpg, cat.jpg, dog.jpg, motorcycle.jpg, truck.jpg\\\")\\nprint(\\\"\\\\n‚è≥ After uploading images, run the next cell...\\\")\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Exploration\n",
    "\n",
    "Let's start by exploring our dataset structure and examining the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display our dataset configuration\n",
    "with open('dataset.yaml', 'r') as f:\n",
    "    dataset_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üéØ Dataset Configuration:\")\n",
    "print(f\"Number of classes: {dataset_config['nc']}\")\n",
    "print(f\"Class names: {list(dataset_config['names'].values())}\")\n",
    "print(f\"Train images path: {dataset_config['train']}\")\n",
    "print(f\"Validation images path: {dataset_config['val']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and display our original base images\n",
    "base_images_path = Path('train/images')\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "\n",
    "# Find all image files\n",
    "all_images = []\n",
    "for ext in image_extensions:\n",
    "    all_images.extend(base_images_path.glob(ext))\n",
    "    all_images.extend(base_images_path.glob(ext.upper()))\n",
    "\n",
    "print(f\"üì∏ Found {len(all_images)} images in the dataset\")\n",
    "\n",
    "# Display original base images\n",
    "if all_images:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Original Base Images', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, img_path in enumerate(all_images[:6]):\n",
    "        if idx >= 6:\n",
    "            break\n",
    "        \n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        \n",
    "        # Load and display image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[row, col].imshow(img_rgb)\n",
    "        axes[row, col].set_title(f\"{img_path.stem}\\n{img.shape[1]}x{img.shape[0]}px\", fontweight='bold')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(all_images), 6):\n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No images found in the train/images directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation\n",
    "\n",
    "Now we'll use our custom augmentation script to create multiple variations of each base image. This is crucial for training a robust YOLO model as it helps the model generalize better to different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine our augmentation script first\n",
    "print(\"üîß Data Augmentation Script Overview:\")\n",
    "print(\"\")\n",
    "print(\"Our augmentation script applies the following transformations:\")\n",
    "print(\"‚Ä¢ üîÑ Rotation: 0-360 degrees (random)\")\n",
    "print(\"‚Ä¢ üìè Scaling: 0.7x to 1.3x (random)\")\n",
    "print(\"‚Ä¢ ‚òÄÔ∏è Brightness: -30 to +30 (random)\")\n",
    "print(\"‚Ä¢ üåà Contrast: 0.7x to 1.3x (random)\")\n",
    "print(\"‚Ä¢ üìª Noise: Added 20% of the time\")\n",
    "print(\"‚Ä¢ üå´Ô∏è Blur: Applied 15% of the time\")\n",
    "print(\"\")\n",
    "print(\"Each transformation creates realistic variations that help the model\")\n",
    "print(\"learn to detect objects under different conditions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set augmentation parameters\n",
    "AUGMENTATIONS_PER_IMAGE = 150  # Adjust this number as needed\n",
    "INPUT_DIR = \"train/images\"      # Directory with original images\n",
    "OUTPUT_DIR = \"train\"           # Output directory for augmented dataset\n",
    "\n",
    "print(f\"‚öôÔ∏è Augmentation Configuration:\")\n",
    "print(f\"Input directory: {INPUT_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Augmentations per image: {AUGMENTATIONS_PER_IMAGE}\")\n",
    "print(f\"Expected total images: {len(all_images) * AUGMENTATIONS_PER_IMAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the augmentation process\n",
    "print(\"üöÄ Starting data augmentation...\")\n",
    "print(\"This may take a few minutes depending on the number of augmentations.\")\n",
    "\n",
    "# Import and use our augmentation class\n",
    "from augment_dataset import YOLODatasetAugmenter\n",
    "\n",
    "# Create augmenter instance\n",
    "augmenter = YOLODatasetAugmenter(INPUT_DIR, OUTPUT_DIR)\n",
    "\n",
    "# Run augmentation\n",
    "augmenter.augment_all_images(AUGMENTATIONS_PER_IMAGE)\n",
    "\n",
    "print(\"\\n‚úÖ Data augmentation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify augmentation results\n",
    "train_images_dir = Path('train/images')\n",
    "train_labels_dir = Path('train/labels')\n",
    "\n",
    "# Count generated files\n",
    "augmented_images = list(train_images_dir.glob('*_[0-9][0-9][0-9].jpg'))\n",
    "augmented_labels = list(train_labels_dir.glob('*_[0-9][0-9][0-9].txt'))\n",
    "original_images = [f for f in train_images_dir.glob('*.jpg') if not f.name.endswith(('_001.jpg', '_002.jpg', '_003.jpg'))]\n",
    "\n",
    "print(f\"üìä Augmentation Results:\")\n",
    "print(f\"Original images: {len(original_images)}\")\n",
    "print(f\"Augmented images: {len(augmented_images)}\")\n",
    "print(f\"Total images: {len(list(train_images_dir.glob('*.jpg')))}\")\n",
    "print(f\"Label files: {len(augmented_labels)}\")\n",
    "print(f\"\")\n",
    "print(f\"Images per class:\")\n",
    "for class_name in ['bird', 'dog', 'cat', 'motorcycle', 'car', 'truck']:\n",
    "    class_images = len(list(train_images_dir.glob(f'{class_name}_*.jpg')))\n",
    "    print(f\"  {class_name}: {class_images} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few examples of augmented images\n",
    "print(\"üñºÔ∏è Sample Augmented Images:\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "fig.suptitle('Sample Augmented Images (Showing Transformations)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Show examples from each class\n",
    "classes = ['bird', 'dog', 'cat', 'motorcycle', 'car', 'truck']\n",
    "sample_count = 0\n",
    "\n",
    "for class_idx, class_name in enumerate(classes):\n",
    "    class_images = list(train_images_dir.glob(f'{class_name}_*.jpg'))[:2]  # Get first 2 augmented images\n",
    "    \n",
    "    for img_idx, img_path in enumerate(class_images):\n",
    "        if sample_count >= 12:  # 3x4 grid\n",
    "            break\n",
    "            \n",
    "        row = sample_count // 4\n",
    "        col = sample_count % 4\n",
    "        \n",
    "        img = cv2.imread(str(img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[row, col].imshow(img_rgb)\n",
    "        axes[row, col].set_title(f\"{class_name.title()}\\n{img_path.name}\", fontweight='bold', fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "        \n",
    "        sample_count += 1\n",
    "    \n",
    "    if sample_count >= 12:\n",
    "        break\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(sample_count, 12):\n",
    "    row = idx // 4\n",
    "    col = idx % 4\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. YOLO Training\n",
    "\n",
    "Now that we have our augmented dataset ready, let's train our YOLO model. We'll use the YOLOv8 architecture, which is state-of-the-art for object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'model_size': 'n',        # Options: 'n', 's', 'm', 'l', 'x' (nano to extra-large)\n",
    "    'epochs': 100,            # Number of training epochs\n",
    "    'imgsz': 640,             # Image size for training\n",
    "    'batch_size': 16,         # Batch size (adjust based on your GPU memory)\n",
    "    'device': device,         # Device determined earlier\n",
    "}\n",
    "\n",
    "print(\"üéØ Training Configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "    \n",
    "print(\"\\nüí° Model Size Guide:\")\n",
    "print(\"  ‚Ä¢ 'n' (nano): Fastest, smallest, good for mobile/edge devices\")\n",
    "print(\"  ‚Ä¢ 's' (small): Good balance of speed and accuracy\")\n",
    "print(\"  ‚Ä¢ 'm' (medium): Better accuracy, moderate speed\")\n",
    "print(\"  ‚Ä¢ 'l' (large): High accuracy, slower inference\")\n",
    "print(\"  ‚Ä¢ 'x' (extra-large): Highest accuracy, slowest inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the YOLO model\n",
    "model_name = f\"yolov8{TRAINING_CONFIG['model_size']}.pt\"\n",
    "print(f\"ü§ñ Loading {model_name} model...\")\n",
    "\n",
    "# Load pre-trained YOLO model\n",
    "model = YOLO(model_name)\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"   Model: YOLOv8{TRAINING_CONFIG['model_size']}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n",
    "print(f\"   Size on disk: {os.path.getsize(model_name) / (1024*1024):.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"üöÄ Starting YOLO training...\")\n",
    "print(\"This will take some time. You can monitor the progress below.\")\n",
    "print(\"Training logs and checkpoints will be saved in 'runs/detect/drone_detection/\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data='dataset.yaml',\n",
    "    epochs=TRAINING_CONFIG['epochs'],\n",
    "    imgsz=TRAINING_CONFIG['imgsz'],\n",
    "    batch=TRAINING_CONFIG['batch_size'],\n",
    "    device=TRAINING_CONFIG['device'],\n",
    "    project='runs/detect',\n",
    "    name='drone_detection',\n",
    "    save_period=10,  # Save checkpoint every 10 epochs\n",
    "    patience=20,     # Early stopping patience\n",
    "    \n",
    "    # Augmentation settings (additional to our pre-generated augmentations)\n",
    "    hsv_h=0.015,     # Hue augmentation\n",
    "    hsv_s=0.7,       # Saturation augmentation  \n",
    "    hsv_v=0.4,       # Value augmentation\n",
    "    degrees=0,       # Don't add rotation (we already did this)\n",
    "    translate=0.1,   # Translation augmentation\n",
    "    scale=0.1,       # Additional scale augmentation\n",
    "    shear=0.1,       # Shear augmentation\n",
    "    perspective=0.0, # Perspective augmentation\n",
    "    flipud=0.0,      # No vertical flip (objects have orientation)\n",
    "    fliplr=0.0,      # No horizontal flip (for consistency)\n",
    "    mosaic=0.8,      # Mosaic augmentation probability\n",
    "    mixup=0.1,       # Mixup augmentation probability\n",
    "    \n",
    "    # Optimization\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.01,        # Initial learning rate\n",
    "    lrf=0.1,         # Final learning rate (lr0 * lrf)\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3,\n",
    "    warmup_momentum=0.8,\n",
    "    warmup_bias_lr=0.1,\n",
    "    \n",
    "    # Other settings\n",
    "    box=7.5,         # Box loss gain\n",
    "    cls=0.5,         # Class loss gain\n",
    "    dfl=1.5,         # DFL loss gain\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Analysis\n",
    "\n",
    "Let's analyze the training results and visualize the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training results exist\n",
    "results_dir = Path('runs/detect/drone_detection3')\n",
    "if results_dir.exists():\n",
    "    print(f\"üìÇ Training results saved in: {results_dir}\")\n",
    "    print(f\"üìÅ Contents:\")\n",
    "    for item in sorted(results_dir.iterdir()):\n",
    "        if item.is_file():\n",
    "            print(f\"  üìÑ {item.name}\")\n",
    "        else:\n",
    "            print(f\"  üìÅ {item.name}/\")\n",
    "else:\n",
    "    print(\"‚ùå Training results not found. Make sure training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves if available\n",
    "results_image_path = results_dir / 'results.png'\n",
    "if results_image_path.exists():\n",
    "    print(\"üìà Training Results:\")\n",
    "    display(Image(str(results_image_path)))\n",
    "else:\n",
    "    print(\"üìà Training curves not found. They should be available after training completes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix if available\n",
    "confusion_matrix_path = results_dir / 'confusion_matrix.png'\n",
    "if confusion_matrix_path.exists():\n",
    "    print(\"üéØ Confusion Matrix:\")\n",
    "    display(Image(str(confusion_matrix_path)))\n",
    "else:\n",
    "    print(\"üéØ Confusion matrix not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display validation results\n",
    "val_batch_path = results_dir / 'val_batch0_labels.jpg'\n",
    "if val_batch_path.exists():\n",
    "    print(\"üîç Validation Batch with Ground Truth Labels:\")\n",
    "    display(Image(str(val_batch_path)))\n",
    "    \n",
    "val_pred_path = results_dir / 'val_batch0_pred.jpg'\n",
    "if val_pred_path.exists():\n",
    "    print(\"\\nü§ñ Validation Batch with Model Predictions:\")\n",
    "    display(Image(str(val_pred_path)))\n",
    "\n",
    "if not val_batch_path.exists() and not val_pred_path.exists():\n",
    "    print(\"üîç Validation images not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and run validation\n",
    "best_model_path = results_dir / 'weights' / 'best.pt'\n",
    "if best_model_path.exists():\n",
    "    print(f\"üèÜ Loading best model: {best_model_path}\")\n",
    "    trained_model = YOLO(str(best_model_path))\n",
    "    \n",
    "    # Run validation\n",
    "    print(\"\\nüî¨ Running final validation...\")\n",
    "    val_results = trained_model.val()\n",
    "    \n",
    "    # Print key metrics\n",
    "    print(\"\\nüìä Final Model Metrics:\")\n",
    "    if hasattr(val_results, 'box'):\n",
    "        metrics = val_results.box\n",
    "        print(f\"  mAP@0.5: {metrics.map50:.3f}\")\n",
    "        print(f\"  mAP@0.5:0.95: {metrics.map:.3f}\")\n",
    "        print(f\"  Precision: {metrics.mp:.3f}\")\n",
    "        print(f\"  Recall: {metrics.mr:.3f}\")\n",
    "else:\n",
    "    print(\"‚ùå Best model not found. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Testing\n",
    "\n",
    "Let's test our trained model on some sample images to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on some training images\n",
    "if 'trained_model' in locals():\n",
    "    print(\"üß™ Testing the trained model on sample images...\")\n",
    "    \n",
    "    # Get some test images\n",
    "    test_images = list(train_images_dir.glob('*_001.jpg'))[:6]  # First augmented image of each class\n",
    "    \n",
    "    if test_images:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('Model Predictions on Sample Images', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        for idx, img_path in enumerate(test_images[:6]):\n",
    "            row = idx // 3\n",
    "            col = idx % 3\n",
    "            \n",
    "            # Run inference\n",
    "            results = trained_model(str(img_path), verbose=False)\n",
    "            \n",
    "            # Get the annotated image\n",
    "            annotated_img = results[0].plot()\n",
    "            annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            axes[row, col].imshow(annotated_img_rgb)\n",
    "            axes[row, col].set_title(f\"{img_path.stem}\", fontweight='bold')\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ùå No test images found.\")\n",
    "else:\n",
    "    print(\"‚ùå Trained model not available. Please complete the training step first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test model on a custom image\n",
    "def test_on_custom_image(image_path, confidence_threshold=0.5):\n",
    "    \"\"\"Test the model on a custom image\"\"\"\n",
    "    if 'trained_model' not in locals():\n",
    "        print(\"‚ùå Trained model not available. Please complete the training step first.\")\n",
    "        return\n",
    "    \n",
    "    if not Path(image_path).exists():\n",
    "        print(f\"‚ùå Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üîç Testing on: {image_path}\")\n",
    "    \n",
    "    # Run inference\n",
    "    results = trained_model(image_path, conf=confidence_threshold, verbose=False)\n",
    "    \n",
    "    # Display results\n",
    "    annotated_img = results[0].plot()\n",
    "    annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(annotated_img_rgb)\n",
    "    plt.title(f'Detection Results - {Path(image_path).name}', fontweight='bold', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detection details\n",
    "    if len(results[0].boxes) > 0:\n",
    "        print(\"\\nüéØ Detections:\")\n",
    "        for i, box in enumerate(results[0].boxes):\n",
    "            class_id = int(box.cls[0])\n",
    "            confidence = float(box.conf[0])\n",
    "            class_name = dataset_config['names'][class_id]\n",
    "            print(f\"  {i+1}. {class_name} (confidence: {confidence:.3f})\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå No objects detected\")\n",
    "\n",
    "# Example usage (uncomment and modify the path to test on your own images)\n",
    "# test_on_custom_image('path/to/your/test/image.jpg', confidence_threshold=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully completed the YOLO training tutorial! Here's what you've accomplished:\n",
    "\n",
    "### ‚úÖ What You've Done:\n",
    "1. **Environment Setup**: Configured all required libraries and dependencies\n",
    "2. **Dataset Exploration**: Examined the original dataset structure and images\n",
    "3. **Data Augmentation**: Generated hundreds of augmented training images with various transformations\n",
    "4. **YOLO Training**: Trained a custom YOLOv8 model on your 6-class dataset\n",
    "5. **Results Analysis**: Evaluated model performance with metrics and visualizations\n",
    "6. **Model Testing**: Tested the trained model on sample images\n",
    "\n",
    "### üìÅ Important Files Created:\n",
    "- `runs/detect/drone_detection/weights/best.pt` - Your best trained model\n",
    "- `runs/detect/drone_detection/weights/last.pt` - Last checkpoint\n",
    "- `runs/detect/drone_detection/results.png` - Training curves\n",
    "- `train/images/` - Augmented training images\n",
    "- `train/labels/` - Corresponding YOLO format labels\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. **Export Your Model**: Convert to different formats (ONNX, TensorRT, etc.) for deployment\n",
    "2. **Create Validation Set**: Prepare a separate validation dataset for final testing\n",
    "3. **Optimize for Deployment**: Experiment with different model sizes and quantization\n",
    "4. **Real-world Testing**: Test on actual drone footage or real-world scenarios\n",
    "\n",
    "### üìö Additional Resources:\n",
    "- [Ultralytics YOLOv8 Documentation](https://docs.ultralytics.com/)\n",
    "- [YOLO Model Export Guide](https://docs.ultralytics.com/modes/export/)\n",
    "- [Advanced Training Techniques](https://docs.ultralytics.com/modes/train/)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy detecting! üéØü§ñ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary cell\n",
    "print(\"üéä TUTORIAL COMPLETED SUCCESSFULLY! üéä\")\n",
    "print(\"\")\n",
    "print(\"Your YOLO model is now trained and ready to use!\")\n",
    "print(f\"Best model saved at: runs/detect/drone_detection/weights/best.pt\")\n",
    "print(\"\")\n",
    "print(\"To use your model in a Python script:\")\n",
    "print(\"\")\n",
    "print(\"```python\")\n",
    "print(\"from ultralytics import YOLO\")\n",
    "print(\"\")\n",
    "print(\"# Load your trained model\")\n",
    "print(\"model = YOLO('runs/detect/drone_detection/weights/best.pt')\")\n",
    "print(\"\")\n",
    "print(\"# Run inference on an image\")\n",
    "print(\"results = model('path/to/your/image.jpg')\")\n",
    "print(\"\")\n",
    "print(\"# Show results\")\n",
    "print(\"results[0].show()\")\n",
    "print(\"```\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}